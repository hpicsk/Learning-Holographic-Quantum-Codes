\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{almheiri2015bulk,pastawski2015holographic}
\citation{pastawski2015holographic}
\citation{ryu2006holographic}
\citation{susskind2016computational,brown2016holographic}
\citation{parker2019universal,barbon2019krylov}
\citation{viswanath1994recursion}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{xu2025hypernq,cao2022neural}
\citation{bak2025learning}
\citation{gottesman1997stabilizer,calderbank1996good}
\citation{pastawski2015holographic}
\citation{viswanath1994recursion,parker2019universal}
\citation{parker2019universal}
\citation{xu2025hypernq}
\citation{tanner1981recursive}
\citation{lu2021learning}
\citation{tancik2020fourier}
\citation{susskind2016computational}
\citation{brown2016holographic}
\citation{lloyd2000ultimate}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{3}{section.2}\protected@file@percent }
\newlabel{sec:background}{{2}{3}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Stabilizer Codes}{3}{subsection.2.1}\protected@file@percent }
\newlabel{sec:stabilizer}{{2.1}{3}{Stabilizer Codes}{subsection.2.1}{}}
\newlabel{eq:projector}{{1}{3}{Stabilizer Codes}{equation.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Krylov Complexity}{3}{subsection.2.2}\protected@file@percent }
\newlabel{sec:krylov}{{2.2}{3}{Krylov Complexity}{subsection.2.2}{}}
\newlabel{eq:lanczos}{{2}{3}{Krylov Complexity}{equation.2.2}{}}
\newlabel{eq:krylov_complexity}{{3}{3}{Krylov Complexity}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Neural Architectures}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Complexity in Holography}{3}{subsection.2.4}\protected@file@percent }
\citation{loshchilov2019decoupled}
\citation{tancik2020fourier}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{4}{section.3}\protected@file@percent }
\newlabel{sec:method}{{3}{4}{Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Code-Space Projection as Initial State}{4}{subsection.3.1}\protected@file@percent }
\newlabel{sec:projection}{{3.1}{4}{Code-Space Projection as Initial State}{subsection.3.1}{}}
\newlabel{eq:initial_state}{{4}{4}{Code-Space Projection as Initial State}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Hypergraph GNN for Code Properties}{4}{subsection.3.2}\protected@file@percent }
\newlabel{sec:gnn}{{3.2}{4}{Hypergraph GNN for Code Properties}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}DeepONet for Complexity Prediction}{4}{subsection.3.3}\protected@file@percent }
\newlabel{sec:deeponet}{{3.3}{4}{DeepONet for Complexity Prediction}{subsection.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces GNN prediction performance on the test set (661 codes, 70/15/15 split). Distance accuracy refers to the percentage of correctly predicted integer distances after rounding.}}{5}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:gnn}{{1}{5}{GNN prediction performance on the test set (661 codes, 70/15/15 split). Distance accuracy refers to the percentage of correctly predicted integer distances after rounding}{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Correlation Analysis}{5}{subsection.3.4}\protected@file@percent }
\newlabel{sec:correlation_method}{{3.4}{5}{Correlation Analysis}{subsection.3.4}{}}
\newlabel{eq:partial}{{6}{5}{Correlation Analysis}{equation.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{5}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{5}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Setup}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}GNN Results}{5}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces DeepONet ablation: GNN embeddings vs.\ simple baselines.}}{6}{table.caption.2}\protected@file@percent }
\newlabel{tab:deeponet}{{2}{6}{DeepONet ablation: GNN embeddings vs.\ simple baselines}{table.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Partial correlations between geometric and dynamic features, controlling for $n_{\mathrm  {physical}}$. Boldface indicates $|r_{\mathrm  {partial}}| > 0.3$.}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:partial}{{3}{6}{Partial correlations between geometric and dynamic features, controlling for $n_{\mathrm {physical}}$. Boldface indicates $|r_{\mathrm {partial}}| > 0.3$}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}DeepONet Ablation and Efficiency}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Geometry--Complexity Correlations}{6}{subsection.4.4}\protected@file@percent }
\newlabel{sec:correlations}{{4.4}{6}{Geometry--Complexity Correlations}{subsection.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Correlation heatmaps. (a) Raw Pearson correlations between geometric and dynamic features. (b) Partial correlations controlling for $n_{\mathrm  {physical}}$. Controlling for system size strengthens the geometry--complexity relationship, revealing that $n$ acts as a suppressor variable.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:heatmap}{{1}{7}{Correlation heatmaps. (a) Raw Pearson correlations between geometric and dynamic features. (b) Partial correlations controlling for $n_{\mathrm {physical}}$. Controlling for system size strengthens the geometry--complexity relationship, revealing that $n$ acts as a suppressor variable}{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Distance--complexity correlations across Hamiltonians. The geometry--complexity link is robust for XXZ and random Hamiltonians but breaks for Ising.}}{7}{table.caption.6}\protected@file@percent }
\newlabel{tab:robustness}{{4}{7}{Distance--complexity correlations across Hamiltonians. The geometry--complexity link is robust for XXZ and random Hamiltonians but breaks for Ising}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Multi-Hamiltonian Robustness}{7}{subsection.4.5}\protected@file@percent }
\newlabel{sec:multi_hamiltonian}{{4.5}{7}{Multi-Hamiltonian Robustness}{subsection.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Within-size scatter plots of code distance vs.\ growth exponent for each system size $n \in \{4, \ldots  , 12\}$. The negative correlation persists at every size and \emph  {strengthens} with increasing $n$, confirming that the geometry--complexity link is not an artifact of system size variation and becomes more pronounced at larger scales. Significance: ${}^{***}p < 0.001$, ${}^{**}p < 0.01$, ${}^{*}p < 0.05$.}}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:scatter}{{2}{8}{Within-size scatter plots of code distance vs.\ growth exponent for each system size $n \in \{4, \ldots , 12\}$. The negative correlation persists at every size and \emph {strengthens} with increasing $n$, confirming that the geometry--complexity link is not an artifact of system size variation and becomes more pronounced at larger scales. Significance: ${}^{***}p < 0.001$, ${}^{**}p < 0.01$, ${}^{*}p < 0.05$}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Holographic Tests}{8}{subsection.4.6}\protected@file@percent }
\citation{viswanath1994recursion}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{9}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{9}{Discussion}{section.5}{}}
\bibstyle{unsrtnat}
\bibdata{references}
\bibcite{almheiri2015bulk}{{1}{2015}{{Almheiri et~al.}}{{Almheiri, Dong, and Harlow}}}
\bibcite{pastawski2015holographic}{{2}{2015}{{Pastawski et~al.}}{{Pastawski, Yoshida, Harlow, and Preskill}}}
\bibcite{ryu2006holographic}{{3}{2006}{{Ryu and Takayanagi}}{{}}}
\bibcite{susskind2016computational}{{4}{2016}{{Susskind}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Framework overview. (a) A hypergraph GNN encodes stabilizer code structure and predicts code properties ($d$, $k/n$). (b) A DeepONet, conditioned on code embeddings and Hamiltonian parameters, predicts Krylov complexity trajectories $C_K(t)$. (c) Partial correlation analysis reveals that code geometry constrains complexity dynamics ($r_{\mathrm  {partial}} = -0.60$, 661 codes, $n \leq 12$).}}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:framework}{{3}{10}{Framework overview. (a) A hypergraph GNN encodes stabilizer code structure and predicts code properties ($d$, $k/n$). (b) A DeepONet, conditioned on code embeddings and Hamiltonian parameters, predicts Krylov complexity trajectories $C_K(t)$. (c) Partial correlation analysis reveals that code geometry constrains complexity dynamics ($r_{\mathrm {partial}} = -0.60$, 661 codes, $n \leq 12$)}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{10}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{10}{Conclusion}{section.6}{}}
\bibcite{brown2016holographic}{{5}{2016}{{Brown et~al.}}{{Brown, Roberts, Susskind, Swingle, and Zhao}}}
\bibcite{parker2019universal}{{6}{2019}{{Parker et~al.}}{{Parker, Cao, Avdoshkin, Scaffidi, and Altman}}}
\bibcite{barbon2019krylov}{{7}{2019}{{Barb{\'o}n et~al.}}{{Barb{\'o}n, Rabinovici, Shir, and Sinha}}}
\bibcite{viswanath1994recursion}{{8}{1994}{{Viswanath and M{\"u}ller}}{{}}}
\bibcite{xu2025hypernq}{{9}{2025}{{Xu and Bhatt}}{{}}}
\bibcite{cao2022neural}{{10}{2022}{{Cao and Lackey}}{{}}}
\bibcite{bak2025learning}{{11}{2025}{{Bak et~al.}}{{Bak, Kim, and Park}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Krylov complexity $C_K(t)$ for different stabilizer codes under the same XXZ Hamiltonian ($n = 5$). Higher-distance codes (e.g., $[[5,1,3]]$) exhibit lower growth rate and saturation value compared to lower-distance codes (e.g., $[[5,1,1]]$). Note that while trajectories are primarily clustered by distance, individual code structure causes some within-distance variation.}}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:krylov_curves}{{4}{11}{Krylov complexity $C_K(t)$ for different stabilizer codes under the same XXZ Hamiltonian ($n = 5$). Higher-distance codes (e.g., $[[5,1,3]]$) exhibit lower growth rate and saturation value compared to lower-distance codes (e.g., $[[5,1,1]]$). Note that while trajectories are primarily clustered by distance, individual code structure causes some within-distance variation}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Robustness of distance--complexity correlations across Hamiltonians. The negative correlation is consistent for XXZ variants and random Hamiltonians but vanishes for the Ising model, whose $ZZ$ symmetry decouples geometry from dynamics.}}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:robustness}{{5}{11}{Robustness of distance--complexity correlations across Hamiltonians. The negative correlation is consistent for XXZ variants and random Hamiltonians but vanishes for the Ising model, whose $ZZ$ symmetry decouples geometry from dynamics}{figure.caption.9}{}}
\bibcite{gottesman1997stabilizer}{{12}{1997}{{Gottesman}}{{}}}
\bibcite{calderbank1996good}{{13}{1996}{{Calderbank and Shor}}{{}}}
\bibcite{tanner1981recursive}{{14}{1981}{{Tanner}}{{}}}
\bibcite{lu2021learning}{{15}{2021}{{Lu et~al.}}{{Lu, Jin, Pang, Zhang, and Karniadakis}}}
\bibcite{tancik2020fourier}{{16}{2020}{{Tancik et~al.}}{{Tancik, Srinivasan, Mildenhall, Fridovich-Keil, Raghavan, Singhal, Ramamoorthi, Barron, and Ng}}}
\bibcite{lloyd2000ultimate}{{17}{2000}{{Lloyd}}{{}}}
\bibcite{loshchilov2019decoupled}{{18}{2019}{{Loshchilov and Hutter}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces DeepONet training dynamics. (a) Training loss converges smoothly. (b) Validation $R^2$ peaks at 0.67 (epoch 15), demonstrating that the code-conditioned operator network successfully learns complexity trajectories.}}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:training}{{6}{12}{DeepONet training dynamics. (a) Training loss converges smoothly. (b) Validation $R^2$ peaks at 0.67 (epoch 15), demonstrating that the code-conditioned operator network successfully learns complexity trajectories}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Dataset Details}{13}{appendix.A}\protected@file@percent }
\newlabel{app:dataset}{{A}{13}{Dataset Details}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Distribution of stabilizer codes by system size.}}{13}{table.caption.11}\protected@file@percent }
\newlabel{tab:dataset}{{5}{13}{Distribution of stabilizer codes by system size}{table.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Architecture Details}{13}{appendix.B}\protected@file@percent }
\newlabel{app:architecture}{{B}{13}{Architecture Details}{appendix.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Complete Correlation Tables}{13}{appendix.C}\protected@file@percent }
\newlabel{app:correlations}{{C}{13}{Complete Correlation Tables}{appendix.C}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Complete partial correlations controlling for $n_{\mathrm  {physical}}$ (661 codes, $n \leq 12$).}}{14}{table.caption.12}\protected@file@percent }
\newlabel{tab:full_partial}{{6}{14}{Complete partial correlations controlling for $n_{\mathrm {physical}}$ (661 codes, $n \leq 12$)}{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Physics Constraint Ablation}{14}{appendix.D}\protected@file@percent }
\newlabel{app:physics}{{D}{14}{Physics Constraint Ablation}{appendix.D}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Theoretical Justification of the Annihilation Mechanism}{14}{appendix.E}\protected@file@percent }
\newlabel{app:annihilation_proof}{{E}{14}{Theoretical Justification of the Annihilation Mechanism}{appendix.E}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Finite-Size Scaling and Multi-Seed Analysis}{15}{appendix.F}\protected@file@percent }
\newlabel{app:scaling}{{F}{15}{Finite-Size Scaling and Multi-Seed Analysis}{appendix.F}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Within-size correlations and scaling trend. The correlation strengthens from $n=4$ to $n=12$, approaching deterministic behavior for $C_K^{\max }$ and $C_{\mathrm  {sat}}$. The $n=7$ anomaly is discussed in the text.}}{15}{table.caption.13}\protected@file@percent }
\newlabel{tab:scaling}{{7}{15}{Within-size correlations and scaling trend. The correlation strengthens from $n=4$ to $n=12$, approaching deterministic behavior for $C_K^{\max }$ and $C_{\mathrm {sat}}$. The $n=7$ anomaly is discussed in the text}{table.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Phase Transition Analysis}{15}{appendix.G}\protected@file@percent }
\newlabel{app:phase}{{G}{15}{Phase Transition Analysis}{appendix.G}{}}
\gdef \@abspage@last{16}
